{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "API Key",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nihalnihalani/Palm-pdf-chatbot/blob/main/Palm_Pdf_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly3qDWiOsc-s"
      },
      "outputs": [],
      "source": [
        "pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "g2lXANwXtRVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "palm.configure(api_key=\"API\")"
      ],
      "metadata": {
        "id": "A0kc2QVusl3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = palm.generate_text(prompt=\"Write a love story\")\n",
        "print(response.result) #  'cold.'"
      ],
      "metadata": {
        "id": "drbZ40ris60m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "J-wXJtsQvmqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Gradio application setup\n",
        "def create_demo():\n",
        "    with gr.Blocks(title= \" PDF Chatbot\",\n",
        "        theme = \"Monochrome\"  # Change the theme here\n",
        "        ) as demo:\n",
        "\n",
        "        # Create a Gradio block\n",
        "\n",
        "        with gr.Column():\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=0.8):\n",
        "                    api_key = gr.Textbox(\n",
        "                        placeholder='Enter your PaLM API key',\n",
        "                        show_label=False,\n",
        "                        interactive=True,\n",
        "                    container=False)\n",
        "\n",
        "                with gr.Column(scale=0.2):\n",
        "                    change_api_key = gr.Button('Update API Key')\n",
        "\n",
        "            with gr.Row():\n",
        "                chatbot = gr.Chatbot(value=[], elem_id='chatbot', height=680)\n",
        "                show_img = gr.Image(label='PDF Preview', tool='select', height=680)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=0.60):\n",
        "                text_input = gr.Textbox(\n",
        "                    show_label=False,\n",
        "                    placeholder=\"Ask your pdf?\",\n",
        "                container=False)\n",
        "\n",
        "            with gr.Column(scale=0.20):\n",
        "                submit_btn = gr.Button('Send')\n",
        "\n",
        "            with gr.Column(scale=0.20):\n",
        "                upload_btn = gr.UploadButton(\"üìÅ Upload PDF\", file_types=[\".pdf\"])\n",
        "\n",
        "\n",
        "        return demo, api_key, change_api_key, chatbot, show_img, text_input, submit_btn, upload_btn\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    demo, api_key, change_api_key, chatbot, show_img, text_input, submit_btn, upload_btn = create_demo()\n",
        "    demo.queue()\n",
        "    demo.launch()"
      ],
      "metadata": {
        "id": "xJ8z405dv2D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    def user(user_message, history):\n",
        "        return \"\", history + [[user_message, None]]\n",
        "\n",
        "    def bot(history):\n",
        "        bot_message = palm.generate_text(prompt=\"msg\")\n",
        "        history[-1][1] = \"\"\n",
        "        for character in bot_message:\n",
        "            history[-1][1] += character\n",
        "            time.sleep(0.05)\n",
        "            yield history\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.queue()\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "jbbIb-zL2oAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import fitz\n",
        "from PIL import Image\n",
        "\n",
        "# Global variables\n",
        "count = 0\n",
        "n = 0\n",
        "chat_history = []\n",
        "chain = ''\n",
        "\n",
        "# Function to set the OpenAI API key\n",
        "def set_api_key(api_key):\n",
        "    \"\"\"\n",
        "    Sets the OpenAI API key in the environment variable.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): The OpenAI API key.\n",
        "\n",
        "    Returns:\n",
        "        str: Message indicating the API key is set.\n",
        "    \"\"\"\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    return 'OpenAI API key is set'\n",
        "\n",
        "# Function to enable the API key input box\n",
        "def enable_api_box():\n",
        "    \"\"\"\n",
        "    Enables the API key input box.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    return\n",
        "\n",
        "# Function to add text to the chat history\n",
        "def add_text(history, text):\n",
        "    \"\"\"\n",
        "    Adds the user's input text to the chat history.\n",
        "\n",
        "    Args:\n",
        "        history (list): List of tuples representing the chat history.\n",
        "        text (str): The user's input text.\n",
        "\n",
        "    Returns:\n",
        "        list: Updated chat history with the new user input.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        raise gr.Error('Enter text')\n",
        "    history.append((text, ''))\n",
        "    return history\n",
        "\n",
        "# Function to process the PDF file and create a conversation chain\n",
        "def process_file(file):\n",
        "    \"\"\"\n",
        "    Processes the uploaded PDF file and creates a conversational retrieval chain.\n",
        "\n",
        "    Args:\n",
        "        file (FileStorage): The uploaded PDF file.\n",
        "\n",
        "    Returns:\n",
        "        ConversationalRetrievalChain: The created conversational retrieval chain.\n",
        "    \"\"\"\n",
        "    if 'OPENAI_API_KEY' not in os.environ:\n",
        "        raise gr.Error('Upload your OpenAI API key')\n",
        "\n",
        "    loader = PyPDFLoader(file.name)\n",
        "    documents = loader.load()\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    pdf_search = Chroma.from_documents(documents, embeddings)\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.3),\n",
        "                                                  retriever=pdf_search.as_retriever(search_kwargs={\"k\": 1}),\n",
        "                                                  return_source_documents=True)\n",
        "    return chain\n",
        "\n",
        "# Function to generate a response based on the chat history and query\n",
        "def generate_response(history, query, btn):\n",
        "    \"\"\"\n",
        "    Generates a response based on the chat history and user's query.\n",
        "\n",
        "    Args:\n",
        "        history (list): List of tuples representing the chat history.\n",
        "        query (str): The user's query.\n",
        "        btn (FileStorage): The uploaded PDF file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Updated chat history with the generated response and the next page number.\n",
        "    \"\"\"\n",
        "    global count, n, chat_history, chain\n",
        "\n",
        "    if not btn:\n",
        "        raise gr.Error(message='Upload a PDF')\n",
        "    if count == 0:\n",
        "        chain = process_file(btn)\n",
        "        count += 1\n",
        "\n",
        "    result = chain({\"question\": query, 'chat_history': chat_history}, return_only_outputs=True)\n",
        "    chat_history.append((query, result[\"answer\"]))\n",
        "    n = list(result['source_documents'][0])[1][1]['page']\n",
        "\n",
        "    for char in result['answer']:\n",
        "        history[-1][-1] += char\n",
        "    return history, \" \"\n",
        "\n",
        "# Function to render a specific page of a PDF file as an image\n",
        "def render_file(file):\n",
        "    \"\"\"\n",
        "    Renders a specific page of a PDF file as an image.\n",
        "\n",
        "    Args:\n",
        "        file (FileStorage): The PDF file.\n",
        "\n",
        "    Returns:\n",
        "        PIL.Image.Image: The rendered page as an image.\n",
        "    \"\"\"\n",
        "    global n\n",
        "    doc = fitz.open(file.name)\n",
        "    page = doc[n]\n",
        "    # Render the page as a PNG image with a resolution of 300 DPI\n",
        "    pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72))\n",
        "    image = Image.frombytes('RGB', [pix.width, pix.height], pix.samples)\n",
        "    return image"
      ],
      "metadata": {
        "id": "0xeh8VSLwR1Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
